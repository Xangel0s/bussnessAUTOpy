# ğŸ” Scraping Debug Guide

## âŒ Problema Actual

**SÃ­ntoma:** El scraping inicia (botÃ³n muestra "Buscando...") pero no retorna resultados.

**Logs observados:**
- âœ… Backend responde a `/scrape/status` con 200 OK
- âŒ PostgreSQL muestra errores: `FATAL: database "admin" does not exist`
- âŒ No se ven leads en la interfaz despuÃ©s de completar

---

## ğŸ”§ Fixes Aplicados

### 1. PostgreSQL Healthcheck Corregido

**Problema:**
```yaml
healthcheck:
  test: ["CMD-SHELL", "pg_isready -U admin"]  # âŒ No especifica la BD
```

**SoluciÃ³n:**
```yaml
healthcheck:
  test: ["CMD-SHELL", "pg_isready -U admin -d leadhunter"]  # âœ… Especifica la BD correcta
```

### 2. Logging Detallado Agregado

**Antes:**
```python
async for lead in scraper.scrape():
    lead_id = await db.insert_lead(lead)
    # Sin logs
```

**DespuÃ©s:**
```python
async for lead in scraper.scrape():
    lead_count += 1
    print(f"ğŸ“ Lead #{lead_count}: {lead.get('nombre', 'Sin nombre')}")
    
    lead_id = await db.insert_lead(lead)
    
    if lead_id:
        print(f"âœ… Lead guardado con ID: {lead_id}")
    else:
        print(f"âš ï¸ Lead duplicado o error al guardar")
```

---

## ğŸ§ª CÃ³mo Debuggear

### 1. Verificar Logs del Backend en Coolify

Busca estos mensajes despuÃ©s de iniciar una bÃºsqueda:

```
âœ… Logs Esperados:
ğŸ” Iniciando scraping: Cafeteria Lima (max: 20)
ğŸ“ Lead #1: CafeterÃ­a Central
âœ… Lead guardado con ID: 1
ğŸ¯ Oportunidad encontrada! Total: 1
ğŸ“ Lead #2: CafÃ© Express
âœ… Lead guardado con ID: 2
...
âœ… Scraping completado: 20 leads, 8 oportunidades
ğŸ Scraping finalizado
```

```
âŒ Logs de Error Posibles:
âŒ Error en scraping: TimeoutError
âŒ Error en scraping: No se encontrÃ³ selector
âŒ Error extrayendo datos: ...
```

### 2. Verificar Estado de PostgreSQL

```bash
# Ver logs de PostgreSQL
# NO deberÃ­a mostrar: FATAL: database "admin" does not exist

# DeberÃ­a mostrar:
database system is ready to accept connections
```

### 3. Probar Endpoints Manualmente

```bash
# 1. Iniciar scraping
curl -X POST https://api.merckout.me/scrape \
  -H "Content-Type: application/json" \
  -d '{"query": "cafeteria lima", "max_results": 5}'

# 2. Ver estado (cada 3 segundos)
watch -n 3 'curl -s https://api.merckout.me/scrape/status | jq'

# 3. Ver leads encontrados
curl https://api.merckout.me/leads | jq

# 4. Ver estadÃ­sticas
curl https://api.merckout.me/stats | jq
```

---

## ğŸ› Posibles Causas del Problema

### 1. Google Maps Bloqueando el Scraper

**SÃ­ntomas:**
- Scraping inicia pero no encuentra resultados
- Timeout al esperar selectores
- PÃ¡gina no carga correctamente

**SoluciÃ³n:**
- Verificar que Playwright puede acceder a Google Maps
- Revisar si Google detecta el bot
- Considerar usar proxies

**Test:**
```python
# Agregar screenshot para debug
await page.screenshot(path="debug.png")
```

### 2. Selectores de Google Maps Cambiaron

**SÃ­ntomas:**
- No encuentra `div[role="feed"]`
- No encuentra `a[href*='/maps/place/']`
- ExtracciÃ³n de datos falla

**SoluciÃ³n:**
- Actualizar selectores en `scraper.py`
- Verificar estructura HTML actual de Google Maps

### 3. Base de Datos No Acepta Inserts

**SÃ­ntomas:**
- Scraping encuentra leads
- Pero no se guardan en la BD
- `insert_lead()` retorna None

**SoluciÃ³n:**
- Verificar conexiÃ³n a PostgreSQL
- Revisar constraints de la tabla (UNIQUE url)
- Ver logs de errores de BD

### 4. Playwright No Puede Iniciar Chromium

**SÃ­ntomas:**
- Error al iniciar browser
- Timeout en `async_playwright()`
- Recursos insuficientes

**SoluciÃ³n:**
- Verificar que el contenedor tiene suficiente RAM (mÃ­n 1GB)
- Revisar que Chromium estÃ¡ instalado
- Verificar permisos de ejecuciÃ³n

---

## ğŸ“‹ Checklist de DiagnÃ³stico

### Backend
- [ ] Logs muestran "ğŸ” Iniciando scraping"
- [ ] Logs muestran "ğŸ“ Lead #X"
- [ ] Logs muestran "âœ… Lead guardado"
- [ ] Logs muestran "ğŸ Scraping finalizado"
- [ ] No hay errores de Playwright
- [ ] No hay errores de BD

### PostgreSQL
- [ ] No muestra "FATAL: database admin does not exist"
- [ ] Healthcheck pasa correctamente
- [ ] Tablas existen (leads, tipificaciones, lead_tracking)
- [ ] Se pueden insertar registros

### Frontend
- [ ] BotÃ³n cambia a "Buscando..."
- [ ] `/scrape/status` muestra `is_running: true`
- [ ] DespuÃ©s de completar, muestra leads
- [ ] EstadÃ­sticas se actualizan

### Scraper
- [ ] Playwright puede iniciar Chromium
- [ ] Puede navegar a Google Maps
- [ ] Encuentra el selector `div[role="feed"]`
- [ ] Encuentra enlaces de negocios
- [ ] Puede extraer datos de cada negocio

---

## ğŸ”§ Comandos de Debug

### Ver Logs en Tiempo Real
```bash
# En Coolify, seguir logs del backend
# Buscar los emojis: ğŸ” ğŸ“ âœ… ğŸ¯ âŒ ğŸ
```

### Probar Scraper Localmente
```python
# test_scraper.py
import asyncio
from scraper import GoogleMapsScraper

async def test():
    scraper = GoogleMapsScraper("cafeteria lima", 5)
    async for lead in scraper.scrape():
        print(f"Lead: {lead['nombre']}")
        print(f"Reclamable: {lead['es_reclamable']}")
        print("---")

asyncio.run(test())
```

### Verificar BD
```sql
-- Conectarse a PostgreSQL
psql -U admin -d leadhunter

-- Ver leads
SELECT id, nombre, es_reclamable, created_at FROM leads ORDER BY id DESC LIMIT 10;

-- Ver estadÃ­sticas
SELECT 
  COUNT(*) as total,
  COUNT(*) FILTER (WHERE es_reclamable = true) as oportunidades
FROM leads;
```

---

## ğŸš€ PrÃ³ximos Pasos

1. **Redeploy** con los fixes aplicados
2. **Monitorear logs** del backend durante una bÃºsqueda
3. **Verificar** que aparecen los mensajes con emojis
4. **Si no aparecen leads:**
   - Revisar si Playwright puede acceder a Google Maps
   - Verificar selectores actuales de Google Maps
   - Considerar agregar screenshots para debug

---

## ğŸ“Š Logs Esperados (Ejemplo Completo)

```
INFO:     Started server process [1]
INFO:     Waiting for application startup.
âš ï¸ Intento 1/5 fallÃ³: the database system is starting up
ğŸ”„ Reintentando en 2 segundos...
âœ… Base de datos inicializada
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3001

INFO:     10.0.4.1:38190 - "POST /scrape HTTP/1.1" 200 OK
ğŸ” Iniciando scraping: cafeteria lima (max: 20)
ğŸ“ Lead #1: CafeterÃ­a Central
âœ… Lead guardado con ID: 1
ğŸ“ Lead #2: CafÃ© Express  
âš ï¸ Lead duplicado o error al guardar
ğŸ“ Lead #3: Lima Coffee
âœ… Lead guardado con ID: 2
ğŸ¯ Oportunidad encontrada! Total: 1
...
âœ… Scraping completado: 15 leads, 6 oportunidades
ğŸ Scraping finalizado

INFO:     10.0.4.1:38190 - "GET /scrape/status HTTP/1.1" 200 OK
INFO:     10.0.4.1:38190 - "GET /leads HTTP/1.1" 200 OK
INFO:     10.0.4.1:38190 - "GET /stats HTTP/1.1" 200 OK
```

---

**Ãšltima actualizaciÃ³n:** 2026-02-07  
**Commit:** 39a02aa  
**Estado:** Debugging en progreso
